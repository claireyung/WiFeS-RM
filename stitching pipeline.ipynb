{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stitching Pipeline\n",
    "\n",
    "In this notebook the input WiFeS spectra (that has already been processed by the PyWiFeS pipeline) is modified so that the source is chosen, background corrected, the red and blue sides are aligned and stitched together, and the variance and bad pixels are also identified. The final result is made into a fits file ready for input into the calibSpec pipeline. If the observations are of the same object they can be combined into the same fits file, and if you would like you can also get plots of the raw data/selected source spaxels.\n",
    "\n",
    "Pipeline created by Claire Yung. The Spectrumv18 object class is from the OzDES RM CalibSpec code written by Janie Hoorman.\n",
    "\n",
    "For this code to work you must input the file names of the pyWiFES processed fits files into two arrays, for the red and blue, ensuring the order is the same so that observations of the same dates are put together.\n",
    "You should also define an output name, and choose the flags to be true or false if you want plots or to combine the fits files. You can also choose the number of pixels to use as the source and the background (these can be viewed in an output plot too)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.interpolate import InterpolatedUnivariateSpline\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "\n",
    "from scipy.spatial.distance import pdist, cdist, squareform\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor, kernels\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from astropy.time import Time\n",
    "plt.rcParams['text.usetex'] = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Spectrumv18(object):\n",
    "    def __init__(self, filepath=None):\n",
    "        assert filepath is not None\n",
    "        self.filepath = filepath\n",
    "        try:\n",
    "            self.data = fits.open(filepath)\n",
    "        except IOError:\n",
    "            print(\"Error: file {0} could not be found\".format(filepath))\n",
    "            exit()\n",
    "        data = fits.open(filepath)\n",
    "        self.combinedFlux = data[0]\n",
    "        self.combinedVariance = data[1]\n",
    "        self.combinedPixels = data[2]\n",
    "        self.numEpochs = int((np.size(data)-2)/2)+1 \n",
    "        self.cdelt1 = self.combinedFlux.header['cdelt3']  # Wavelength interval between subsequent pixels\n",
    "        self.crpix1 = 1 #self.combinedFlux.header['crpix3']\n",
    "        self.crval1 = self.combinedFlux.header['crval3']\n",
    "        self.n_pix = self.combinedFlux.header['NAXIS3']\n",
    "        self.RA = self.combinedFlux.header['RA']\n",
    "        self.DEC = self.combinedFlux.header['DEC']\n",
    "\n",
    "        self.fluxCoadd = self.combinedFlux.data\n",
    "        self.varianceCoadd = self.combinedVariance.data\n",
    "        self.badpixCoadd = self.combinedPixels.data\n",
    "\n",
    "        self._wavelength = None\n",
    "        self._flux = None\n",
    "        self._variance = None\n",
    "        self._badpix = None\n",
    "        self._dates = None\n",
    "        self._run = None\n",
    "        self._ext = None\n",
    "        self._qc = None\n",
    "        self._exposed = None\n",
    "\n",
    "    @property\n",
    "    def wavelength(self):\n",
    "        \"\"\"Define wavelength solution.\"\"\"\n",
    "        if getattr(self, '_wavelength', None) is None:\n",
    "            wave = ((np.arange(self.n_pix) - self.crpix1) * self.cdelt1) + self.crval1\n",
    "            self._wavelength = wave\n",
    "        return self._wavelength\n",
    "\n",
    "    @property\n",
    "    def flux(self):\n",
    "        if getattr(self, '_flux', None) is None:\n",
    "            self._flux = np.zeros((len(self.data[0].data), self.numEpochs), dtype=float) #2848 or 5000\n",
    "            for i in range(self.numEpochs):\n",
    "                self._flux[:, i] = self.data [i * 2].data     \n",
    "        return self._flux\n",
    "\n",
    "    @property\n",
    "    def variance(self):\n",
    "        if getattr(self, '_variance', None) is None:\n",
    "            self._variance = np.zeros((len(self.data[0].data), self.numEpochs), dtype=float)\n",
    "            for i in range(self.numEpochs):\n",
    "                self._variance[:, i] = self.data[i * 2 + 1].data\n",
    "        return self._variance\n",
    "\n",
    "    @property\n",
    "    def badpix(self):\n",
    "        if getattr(self, '_badpix', None) is None:\n",
    "            self._badpix = np.zeros((len(self.data[0].data), self.numEpochs), dtype=float)\n",
    "            for i in range(self.numEpochs):\n",
    "                self._badpix[:, i] = self.data[i * 2 + 2].data\n",
    "        return self._badpix\n",
    "\n",
    "    @property\n",
    "    def dates(self):\n",
    "        if getattr(self, '_dates', None) is None:\n",
    "            self._dates = np.zeros(self.numEpochs, dtype=float)\n",
    "            for i in range(self.numEpochs):\n",
    "                self._dates[i] = round(Time(self.data[i*3].header['DATE-OBS'], format='isot', scale='utc').mjd,3)\n",
    "                print('date:')\n",
    "                print(self._dates)\n",
    "                # this give Modified Julian Date (UTC) that observation was taken\n",
    "        return self._dates\n",
    "    \n",
    "    @property\n",
    "    def exposed(self):\n",
    "        if getattr(self, '_exposed', None) is None:\n",
    "            self._exposed = []\n",
    "            for i in range(self.numEpochs):\n",
    "                self._exposed.append(self.data[i * 2].header['EXPTIME']) \n",
    "                # this will give you the exposure time of each observation\n",
    "        return self._exposed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "##CONFIGURATIONS##\n",
    "\n",
    "PlotFlag = True #Choose whether to make plots\n",
    "CombineFlag = True #choose whether it's the same object (combine files)\n",
    "n_source = 1 #Number of pixels to use as the source - the brightest n_source pixels will be used. Unless you have a large source\n",
    "            #avoid using more than 9 pixels.\n",
    "n_back = 50 #the least bright n_back pixels will be used. Default 50. To minimise error don't use fewer than 20, or more than 80.\n",
    "#Now input the file names of the fits files you would like to process. These should be the output of pyWiFeS. Make\n",
    "#sure they are in the same order of dates.\n",
    "sourceNamesblue = np.array(['AGNData/T2m3wb-20200530.101942-0029.p11.fits','AGNData/T2m3wb-20200531.103610-0028.p11.fits'])\n",
    "sourceNamesred = np.array(['AGNData/T2m3wr-20200530.101942-0029.p11.fits','AGNData/T2m3wr-20200531.103610-0028.p11.fits'])\n",
    "outName = 'AGNData/IRAS09149-6206-'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Data to AGNData/IRAS09149-6206-0_stitched.fits\n",
      "date:\n",
      "[58999.427]\n",
      "Saving Data to AGNData/IRAS09149-6206-1_stitched.fits\n",
      "date:\n",
      "[59000.438]\n",
      ":)\n",
      "Writing combined output to AGNData/IRAS09149-6206-_stitched_combined.fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2461231eeb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x246126647b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x246122e8d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##PROCESSING##\n",
    "\n",
    "#First we check that you've added the sourceNames correctly.\n",
    "if len(sourceNamesblue) !=len(sourceNamesred):\n",
    "    print('Error - check that your source names are the same length')\n",
    "\n",
    "for j in np.arange(len(sourceNamesblue)):\n",
    "    \n",
    "    blue_spectra = Spectrumv18(sourceNamesblue[j])\n",
    "    red_spectra = Spectrumv18(sourceNamesred[j])\n",
    "    n_b = blue_spectra.n_pix\n",
    "    n_r = red_spectra.n_pix\n",
    "    ##Let's choose the source pixels (n_source brightest pixels) and load their data\n",
    "    a =  np.mean(blue_spectra.fluxCoadd, axis = 0)[1:36,1:23]\n",
    "    if n_source < 1:\n",
    "        print(\"Error - n_source must be greater than or equal to 1\")\n",
    "    if n_source ==1:\n",
    "        ind = np.unravel_index(np.argmax(a, axis=None), a.shape)\n",
    "        blue = blue_spectra.fluxCoadd[np.arange(0,n_b,1), np.ones(n_b).astype(int)*(ind[0]+1), np.ones(n_b).astype(int)*(ind[1]+1)]\n",
    "        red = red_spectra.fluxCoadd[np.arange(0,n_r,1), np.ones(n_r).astype(int)*(ind[0]+1), np.ones(n_r).astype(int)*(ind[1]+1)]\n",
    "        if PlotFlag ==True:\n",
    "            plt.imshow(a)\n",
    "            plt.plot(np.array([ind[1]]),np.array([ind[0]]),color = 'r',marker = \"s\" )\n",
    "            plt.title('Selected regions of the source'+str(j))\n",
    "            plt.savefig(outName+'_selected_regions'+str(j))\n",
    "            plt.clf()\n",
    "        \n",
    "    if n_source >1:    \n",
    "        indices_source = np.unravel_index(np.argsort(a, axis=None)[-n_source:], a.shape)\n",
    "        if PlotFlag ==True:\n",
    "            image = np.zeros([36,23])\n",
    "            image[indices_source]=1\n",
    "            plt.contour(image, levels = [0.5])\n",
    "            plt.imshow(a)\n",
    "            plt.title('Selected regions of the source'+str(j))\n",
    "            plt.savefig(outName+'_selected_regions'+str(j), dpi = 600)\n",
    "            plt.clf()\n",
    "    \n",
    "        blue = [np.zeros(n_b)]\n",
    "        for i in np.arange(0,n_source-1,1):\n",
    "            arr_i = blue_spectra.fluxCoadd[np.arange(0,n_b,1), np.ones(n_b).astype(int)*indices_source[0][i]+1, np.ones(n_b).astype(int)*indices_source[1][i]+1]\n",
    "            blue = np.append(blue,[arr_i], axis = 0)\n",
    "        blue = np.mean(blue[1:], axis = 0)\n",
    "        red = [np.zeros(n_r)]\n",
    "        for i in np.arange(0,n_source-1,1):\n",
    "            arr_i = red_spectra.fluxCoadd[np.arange(0,n_r,1), np.ones(n_r).astype(int)*indices_source[0][i]+1, np.ones(n_r).astype(int)*indices_source[1][i]+1]\n",
    "            red = np.append(red,[arr_i], axis = 0)\n",
    "        red = np.mean(red[1:], axis = 0)\n",
    "    \n",
    "    ##Now let's choose the background pixels by getting the coordinates of the n_back least intense spaxels\n",
    "    def get_indices_of_k_smallest(arr, k):\n",
    "        idx = np.argpartition(arr.ravel(), k)\n",
    "        return tuple(np.array(np.unravel_index(idx, arr.shape))[:, range(min(k, 0), max(k, 0))])\n",
    "    indices = get_indices_of_k_smallest(a, n_back)\n",
    "\n",
    "    background_blue = [np.zeros(n_b)]\n",
    "    for i in np.arange(0,n_back-1,1):\n",
    "        arr_i = blue_spectra.fluxCoadd[np.arange(0,n_b,1), np.ones(n_b).astype(int)*indices[0][i]+1, np.ones(n_b).astype(int)*indices[1][i]+1]\n",
    "        background_blue = np.append(background_blue,[arr_i], axis = 0)\n",
    "    background_blue = np.mean(background_blue[1:], axis = 0)\n",
    "    blue = blue - background_blue\n",
    "\n",
    "    background_red = [np.zeros(n_r)]\n",
    "    for i in np.arange(0,n_back-1,1):\n",
    "        arr_i = red_spectra.fluxCoadd[np.arange(0,n_r,1), np.ones(n_r).astype(int)*indices[0][i]+1, np.ones(n_r).astype(int)*indices[1][i]+1]\n",
    "        background_red = np.append(background_red,[arr_i], axis = 0)\n",
    "    background_red = np.mean(background_red[1:], axis = 0)\n",
    "    red = red - background_red\n",
    "\n",
    "    blue[blue < 0] = 0\n",
    "    red[red < 0]=0 \n",
    "    #red and blue are the arrays of fluxes for the source pixels\n",
    "    \n",
    "    if PlotFlag == True:\n",
    "        plt.plot(blue_spectra.wavelength, blue)\n",
    "        plt.plot(red_spectra.wavelength, red,  color = 'r')\n",
    "        plt.title('Background corrected spectrum of each side'+str(j))\n",
    "        plt.xlabel('Wavelength ($\\AA$)')\n",
    "        plt.savefig(outName+'_background_corrected'+str(j), dpi = 600)\n",
    "        plt.clf()\n",
    "    \n",
    "    #Now we stitch the red and blue sides together:\n",
    "    overlap_blue = blue_spectra.wavelength[blue_spectra.wavelength > red_spectra.wavelength[0] ]\n",
    "    overlap_red = red_spectra.wavelength[red_spectra.wavelength < blue_spectra.wavelength[-1] ]\n",
    "    #The difference in the average of twice the overlap length on the long wavelength side of blue and short side of red\n",
    "    difference = np.mean(red[len(overlap_red):2*len(overlap_red)]) - np.mean(blue[-2*len(overlap_blue):-len(overlap_blue)])\n",
    "    red_shifted = red-difference\n",
    "    #We then average the data in the overlap region\n",
    "    interpolated_red_overlap = np.interp(blue_spectra.wavelength[-len(overlap_blue):],\n",
    "                                     red_spectra.wavelength[:len(overlap_red)],red_shifted[:len(overlap_red)])\n",
    "    overlap_average = np.mean([blue[-len(overlap_blue):],interpolated_red_overlap],axis =0)\n",
    "    final_spectrum = np.append(np.append(blue[:-len(overlap_blue)],overlap_average),red_shifted[len(overlap_red):])\n",
    "    final_wavelengths = np.append(blue_spectra.wavelength,red_spectra.wavelength[len(overlap_red):])\n",
    "    \n",
    "    ##Now we repeat for the source variance\n",
    "    if n_source ==1:\n",
    "        blue_variance = blue_spectra.varianceCoadd[np.arange(0,n_b,1), np.ones(n_b).astype(int)*(ind[0]+1), np.ones(n_b).astype(int)*(ind[1]+1)]\n",
    "        red_variance = red_spectra.varianceCoadd[np.arange(0,n_r,1), np.ones(n_r).astype(int)*(ind[0]+1), np.ones(n_r).astype(int)*(ind[1]+1)]\n",
    "\n",
    "    if n_source >1:\n",
    "        blue_variance = [np.zeros(n_b)]\n",
    "        for i in np.arange(0,n_source-1,1):\n",
    "            arr_i = blue_spectra.varianceCoadd[np.arange(0,n_b,1), np.ones(n_b).astype(int)*indices_source[0][i]+1, np.ones(n_b).astype(int)*indices_source[1][i]+1]\n",
    "            blue_variance = np.append(blue_variance,[arr_i], axis = 0)\n",
    "        blue_variance = np.sqrt(np.sum((blue_variance[1:])**2, axis = 0))/np.sqrt(n_source)\n",
    "        red_variance = [np.zeros(n_r)]\n",
    "        for i in np.arange(0,n_source-1,1):\n",
    "            arr_i = red_spectra.varianceCoadd[np.arange(0,n_r,1), np.ones(n_r).astype(int)*indices_source[0][i]+1, np.ones(n_r).astype(int)*indices_source[1][i]+1]\n",
    "            red_variance = np.append(red_variance,[arr_i], axis = 0)\n",
    "        red_variance = np.sqrt(np.sum((red_variance[1:])**2, axis = 0))/np.sqrt(n_source)\n",
    "\n",
    "#background variance\n",
    "    background_blue_variance = [np.zeros(n_b)]\n",
    "    for i in np.arange(0,n_back-1,1):\n",
    "        arr_i = blue_spectra.varianceCoadd[np.arange(0,n_b,1), np.ones(n_b).astype(int)*indices[0][i]+1, np.ones(n_b).astype(int)*indices[1][i]+1]\n",
    "        background_blue_variance = np.append(background_blue_variance,[arr_i], axis = 0)\n",
    "    background_blue_variance = np.sqrt(np.sum((background_blue_variance[1:])**2, axis = 0))/np.sqrt(n_back)\n",
    "\n",
    "##I use standard error in the mean, which assumes samples come from same background population - this seems reasonable given would\n",
    "## expect background spectrum to be uniform on the camera, except for any issues in the pixels themselves (which would probably \n",
    "##come up as a nonzero value in \"badpix\")\n",
    "\n",
    "    blue_variance = np.sqrt(blue_variance**2 + background_blue_variance**2)\n",
    "    background_red_variance = [np.zeros(n_r)]\n",
    "    for i in np.arange(0,n_back-1,1):\n",
    "        arr_i = red_spectra.varianceCoadd[np.arange(0,n_r,1), np.ones(n_r).astype(int)*indices[0][i]+1, np.ones(n_r).astype(int)*indices[1][i]+1]\n",
    "        background_red_variance = np.append(background_red_variance,[arr_i], axis = 0)\n",
    "    background_red_variance = np.sqrt(np.sum((background_red_variance[1:])**2, axis = 0))/np.sqrt(n_back)\n",
    "    red_variance = np.sqrt(red_variance**2 + background_red_variance**2)\n",
    "    blue_variance[blue_variance < 0] = 0\n",
    "    red_variance[red_variance < 0]=0\n",
    "\n",
    "    overlap_interpolated_variance = np.interp(blue_spectra.wavelength[-len(overlap_blue):],\n",
    "                                     red_spectra.wavelength[:len(overlap_red)],red_variance[:len(overlap_red)])+blue_variance[-len(overlap_blue):]\n",
    "    final_spectrum_variance = np.append(np.append(blue_variance[:-len(overlap_blue)],overlap_interpolated_variance),red_variance[len(overlap_red):])\n",
    "    final_wavelengths_variance = np.append(blue_spectra.wavelength,red_spectra.wavelength[len(overlap_red):])\n",
    "    \n",
    "    ##Now we look at the bad pixels. Since WiFes has badpix for every wavelength, we average the badpix value (0 or 1) over all wavelengths\n",
    "    #for each spaxel. If the spaxel has an average badpix value of above 0.1 it counts as a bad pixel\n",
    "    blue_badpix = np.mean(np.mean(blue_spectra.badpixCoadd, axis = 1), axis = 1)\n",
    "    red_badpix = np.mean(np.mean(red_spectra.badpixCoadd, axis = 1), axis = 1)\n",
    "    spectrum_badpix = np.append(blue_badpix,red_badpix[len(overlap_red):])\n",
    "\n",
    "    def filter_function(x):\n",
    "        if x > 0.1:\n",
    "            return 1\n",
    "        else :\n",
    "            return 0\n",
    "    \n",
    "    final_spectrum_badpix = list(map(lambda x: filter_function(x), spectrum_badpix))\n",
    "    if PlotFlag ==True:\n",
    "        \n",
    "        fig, axs = plt.subplots(3, 1, sharex=True, figsize = (6,5))\n",
    "        fig.subplots_adjust(hspace=0)\n",
    "        fig.suptitle('Final stitched spectrum '+str(j))\n",
    "        axs[0].plot(final_wavelengths, final_spectrum)\n",
    "        axs[0].set_ylabel('Flux')\n",
    "\n",
    "        axs[1].plot(final_wavelengths, final_spectrum_variance)\n",
    "        axs[1].set_ylabel('Variance')\n",
    "        axs[2].plot(final_wavelengths, final_spectrum_badpix)\n",
    "        axs[2].set_xlabel('Wavelength ($\\AA$)')\n",
    "        axs[2].set_ylabel('Badpix')        \n",
    "        \n",
    "        fig.savefig(outName+'_spectrumvariancebadpix'+str(j), dpi = 600)\n",
    "        plt.clf()\n",
    "    \n",
    "    #And now we make the data into a fits file, for input into the calibSpec pipeline.\n",
    "    \n",
    "    outputName = outName+str(j)+\"_stitched.fits\"\n",
    "    print(\"Saving Data to \" + outputName)\n",
    "    hdulist = fits.HDUList(fits.PrimaryHDU())\n",
    "    header = fits.Header()\n",
    "    header['SOURCE'] = outputName\n",
    "    header['RA'] = blue_spectra.RA\n",
    "    header['DEC'] = blue_spectra.DEC\n",
    "    header['CTYPE1'] = 'wavelength'\n",
    "    header['CUNIT1'] = 'angstrom'\n",
    "    header['DATE-OBS'] = blue_spectra.dates[0]\n",
    "    header['EXPTIME'] = blue_spectra.exposed[0]\n",
    "    hdulist[0].data = final_wavelengths\n",
    "    hdulist.append(fits.ImageHDU(data=final_spectrum, header=header))\n",
    "    hdulist.append(fits.ImageHDU(data=final_spectrum_variance, header=header))\n",
    "    hdulist.append(fits.ImageHDU(data=final_spectrum_badpix, header=header))\n",
    "    hdulist.writeto(outputName, overwrite=True)\n",
    "    hdulist.close()\n",
    "\n",
    "    #If desired we can put all the observations of the source together in one fits file:\n",
    "if CombineFlag == True:\n",
    "    hdulist = fits.HDUList(fits.PrimaryHDU())\n",
    "    image_file = outName+str(0)+\"_stitched.fits\"\n",
    "    hdul = fits.open(image_file)\n",
    "    wavelengths = hdul[0]\n",
    "    flux = hdul[1]\n",
    "    variance = hdul[2]\n",
    "    badpix = hdul[3]\n",
    "    hdulist[0].data=wavelengths.data\n",
    "    hdulist.append(fits.ImageHDU(data=flux.data, header=flux.header))\n",
    "    hdulist.append(fits.ImageHDU(data=variance.data, header=variance.header))\n",
    "    hdulist.append(fits.ImageHDU(data=badpix.data, header=badpix.header))   \n",
    "    for j in np.arange(len(sourceNamesblue)):\n",
    "        if j ==0:\n",
    "            print(':)')\n",
    "        else:\n",
    "            image_file = outName+str(j)+\"_stitched.fits\"\n",
    "            hdul = fits.open(image_file)\n",
    "            wavelengths1 = hdul[0]\n",
    "            flux1 = hdul[1]\n",
    "            variance1 = hdul[2]\n",
    "            badpix1 = hdul[3]\n",
    "            if len(wavelengths1.data)==len(wavelengths.data): \n",
    "                hdulist.append(fits.ImageHDU(data=flux1.data, header=flux1.header))\n",
    "                hdulist.append(fits.ImageHDU(data=variance1.data, header=variance1.header))\n",
    "                hdulist.append(fits.ImageHDU(data=badpix1.data, header=badpix1.header))   \n",
    "                \n",
    "                ##Sometimes the observations have slightly different wavelength arrays. We choose to use the first observation\n",
    "                ##wavelength since the difference will be only one or so wavelengths - negligible. If it is longer we remove from \n",
    "                ##the red side, if it is shorter we pad with the mean.\n",
    "            elif len(wavelengths1.data) < len(wavelengths.data):\n",
    "                flux2 = flux1.data\n",
    "                variance2 = variance1.data\n",
    "                badpix2 = badpix1.data\n",
    "                flux2 = np.pad(flux2, (0, len(wavelengths.data)-len(wavelengths1.data)), 'mean')\n",
    "                variance2 = np.pad(variance2, (0, len(wavelengths.data)-len(wavelengths1.data)), 'mean')\n",
    "                badpix2 = np.pad(badpix2, (0, len(wavelengths.data)-len(wavelengths1.data)), 'constant',constant_values=0)\n",
    "                hdulist.append(fits.ImageHDU(data=flux2, header=flux1.header))\n",
    "                hdulist.append(fits.ImageHDU(data=variance2, header=variance1.header))\n",
    "                hdulist.append(fits.ImageHDU(data=badpix2, header=badpix1.header))  \n",
    "            elif len(wavelengths1.data) > len(wavelengths.data):\n",
    "                flux2 = flux1.data\n",
    "                variance2 = variance1.data\n",
    "                badpix2 = badpix1.data\n",
    "                flux2 = flux2[:len(wavelengths.data)]\n",
    "                variance2 = variance2[:len(wavelengths.data)]\n",
    "                badpix2 = badpix2[:len(wavelengths.data)]\n",
    "                hdulist.append(fits.ImageHDU(data=flux2, header=flux1.header))\n",
    "                hdulist.append(fits.ImageHDU(data=variance2, header=variance1.header))\n",
    "                hdulist.append(fits.ImageHDU(data=badpix2, header=badpix1.header))  \n",
    "                \n",
    "    outputname = outName+\"_stitched_combined.fits\"\n",
    "    print('Writing combined output to '+outputname)\n",
    "    hdulist.writeto(outputname, overwrite=True)\n",
    "    hdulist.close()\n",
    "\n",
    "\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
